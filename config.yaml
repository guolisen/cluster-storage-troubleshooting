# LLM Configuration
llm:
  model: "gpt4-o4-mini"
  api_endpoint: "https://x.ai/api"
  api_key: ''
  temperature: 0.7
  max_tokens: 1000

# Monitoring Configuration
monitor:
  interval_seconds: 60
  api_retries: 3
  retry_backoff_seconds: 5

# Troubleshooting Configuration
troubleshoot:
  timeout_seconds: 300
  interactive_mode: true
  ssh:
    enabled: true
    user: "admin"
    key_path: "/path/to/ssh/key"
    nodes:
      - "workernode1"
      - "workernode2"
      - "masternode1"
    retries: 3
    retry_backoff_seconds: 5

# Allowed Commands
commands:
  allowed:
    - "kubectl get pod"
    - "kubectl describe pod"
    - "kubectl logs"
    - "kubectl get pvc"
    - "kubectl get pv"
    - "kubectl get storageclass"
    - "kubectl get csidrivers"
    - "kubectl get drive"
    - "kubectl get csibmnode"
    - "kubectl get ac"
    - "kubectl get lvg"
    - "kubectl top node"
    - "kubectl describe node"
    - "df -h"
    - "lsblk"
    - "cat /proc/mounts"
    - "smartctl -a"
    - "fio --name=read_test"
    - "fio --name=write_test"
    - "dmesg | grep -i disk"
    - "dmesg | grep -i error"
    - "dmesg | grep -i xfs"
    - "journalctl -u kubelet"
  disallowed:
    - "fsck"
    - "chmod"
    - "chown"
    - "dd"
    - "mkfs"
    - "rm"
    - "kubectl delete pod"
    - "kubectl delete pvc"
    - "kubectl delete volume"
    - "kubectl delete pv"

# Logging Configuration
logging:
  file: "troubleshoot.log"
  stdout: true
