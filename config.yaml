# LLM Configuration
llm:
  model: "gpt4-o4-mini"
  api_endpoint: "https://x.ai/api"
  api_key: ''
  temperature: 0.7
  max_tokens: 1000

# Monitoring Configuration
monitor:
  interval_seconds: 60
  api_retries: 3
  retry_backoff_seconds: 5

# Troubleshooting Configuration
troubleshoot:
  timeout_seconds: 300
  interactive_mode: true
  auto_fix: false  # Enable/disable auto-fix mode
  ssh:
    enabled: true
    user: "admin"
    key_path: "/path/to/ssh/key"
    nodes:
      - "workernode1"
      - "workernode2"
      - "masternode1"
    retries: 3
    retry_backoff_seconds: 5

# Allowed Commands (supports prefix/wildcard)
commands:
  allowed:
    - "kubectl get *"
    - "kubectl describe *"
    - "kubectl logs *"
    - "kubectl exec *"
    - "kubectl top *"
    - "df -h"
    - "lsblk"
    - "cat /proc/mounts"
    - "smartctl -a *"
    - "fio --name=read_test *"
    - "fio --name=write_test *"
    - "dmesg | grep -i disk"
    - "dmesg | grep -i error"
    - "dmesg | grep -i xfs"
    - "journalctl -u kubelet *"
    - "xfs_repair -n *"  # Diagnostic mode only
  disallowed:
    - "fsck *"
    - "chmod *"
    - "chown *"
    - "dd *"
    - "mkfs *"
    - "rm *"
    - "kubectl delete *"
    - "kubectl apply *"
    - "xfs_repair *"  # Disallow non-diagnostic xfs_repair

# Logging Configuration
logging:
  file: "troubleshoot.log"
  stdout: true
