# Comprehensive Mode Guide

This guide explains the comprehensive troubleshooting mode that uses knowledge graphs to analyze ALL related storage issues across the Kubernetes cluster.

## ­Ъј» Overview

Comprehensive Mode transforms the troubleshooting approach from single-issue focused to ecosystem-wide analysis:

- **Traditional Approach**: "Meet one issue Рєњ Give final response"
- **Comprehensive Approach**: "Collect ALL related issues Рєњ Build knowledge graph Рєњ Comprehensive analysis"

## ­ЪЈЌ№ИЈ Architecture

```mermaid
graph TB
    subgraph "Comprehensive Mode Architecture"
        Input[Pod Volume I/O Error] --> Collector[ComprehensiveIssueCollector]
        
        subgraph "Knowledge Graph Engine"
            KG[IssueKnowledgeGraph]
            Nodes[IssueNode Collection]
            Relations[Relationship Mapping]
        end
        
        subgraph "Issue Discovery Layers"
            PodLayer[Pod Layer Discovery]
            NodeLayer[Node Layer Discovery]
            StorageLayer[Storage Layer Discovery]
            CSILayer[CSI Driver Discovery]
            SystemLayer[System Layer Discovery]
        end
        
        subgraph "Analysis Engine"
            RootCause[Root Cause Analysis]
            CascadeAnalysis[Cascading Failure Analysis]
            Clustering[Issue Clustering]
            Prioritization[Fix Prioritization]
        end
        
        Collector --> KG
        KG --> Nodes
        Nodes --> Relations
        
        Collector --> PodLayer
        Collector --> NodeLayer
        Collector --> StorageLayer
        Collector --> CSILayer
        Collector --> SystemLayer
        
        Relations --> RootCause
        RootCause --> CascadeAnalysis
        CascadeAnalysis --> Clustering
        Clustering --> Prioritization
        
        Prioritization --> Output[Comprehensive Results]
    end
```

## ­ЪћЇ Issue Discovery Process

### Layer-by-Layer Analysis

```mermaid
flowchart TD
    Start([Primary Pod Issue]) --> L1[Pod Layer Analysis]
    
    subgraph "Pod Layer"
        L1 --> P1[Pod Status & Events]
        L1 --> P2[Container Logs]
        L1 --> P3[Volume Mounts]
        L1 --> P4[Resource Constraints]
    end
    
    P1 --> L2[Node Layer Analysis]
    P2 --> L2
    P3 --> L2
    P4 --> L2
    
    subgraph "Node Layer"
        L2 --> N1[Node Conditions]
        L2 --> N2[Kubelet Status]
        L2 --> N3[System Resources]
        L2 --> N4[Mount Points]
    end
    
    N1 --> L3[Storage Layer Analysis]
    N2 --> L3
    N3 --> L3
    N4 --> L3
    
    subgraph "Storage Layer"
        L3 --> S1[Physical Drives]
        L3 --> S2[File Systems]
        L3 --> S3[I/O Performance]
        L3 --> S4[SMART Status]
    end
    
    S1 --> L4[CSI Driver Analysis]
    S2 --> L4
    S3 --> L4
    S4 --> L4
    
    subgraph "CSI Layer"
        L4 --> C1[CSI Controller]
        L4 --> C2[CSI Node Driver]
        L4 --> C3[Volume Attachments]
        L4 --> C4[Storage Classes]
    end
    
    C1 --> L5[System Layer Analysis]
    C2 --> L5
    C3 --> L5
    C4 --> L5
    
    subgraph "System Layer"
        L5 --> SYS1[Kernel Messages]
        L5 --> SYS2[System Services]
        L5 --> SYS3[Network Connectivity]
        L5 --> SYS4[Security Policies]
    end
    
    SYS1 --> Knowledge[Knowledge Graph Building]
    SYS2 --> Knowledge
    SYS3 --> Knowledge
    SYS4 --> Knowledge
```

## ­ЪДа Knowledge Graph Components

### Issue Types Classification

```mermaid
graph LR
    subgraph "Issue Categories"
        Pod[POD_MOUNT_ERROR<br/>POD_IO_ERROR<br/>POD_RESOURCE_LIMIT]
        Node[NODE_DISK_FULL<br/>NODE_UNAVAILABLE<br/>NODE_NETWORK_ERROR]
        Storage[DRIVE_FAILURE<br/>FILESYSTEM_CORRUPTION<br/>IO_PERFORMANCE_DEGRADED]
        CSI[CSI_DRIVER_ERROR<br/>CSI_VOLUME_ATTACH_FAILED<br/>CSI_PROVISIONING_ERROR]
        Network[NETWORK_TIMEOUT<br/>NETWORK_UNREACHABLE<br/>NETWORK_BANDWIDTH_LIMIT]
        System[KERNEL_ERROR<br/>SERVICE_DOWN<br/>PERMISSION_DENIED]
    end
```

### Severity Levels

```mermaid
graph TD
    Critical[CRITICAL<br/>System Down<br/>Data Loss Risk] --> High[HIGH<br/>Service Degraded<br/>User Impact]
    High --> Medium[MEDIUM<br/>Performance Issues<br/>Intermittent Problems]
    Medium --> Low[LOW<br/>Warnings<br/>Potential Issues]
```

### Relationship Types

```mermaid
graph LR
    IssueA[Issue A] -->|CAUSES| IssueB[Issue B]
    IssueA -->|AFFECTS| IssueC[Issue C]
    IssueA -->|RELATED_TO| IssueD[Issue D]
    IssueA -->|DEPENDS_ON| IssueE[Issue E]
```

## ­ЪЊі Analysis Algorithms

### Root Cause Identification

```mermaid
flowchart TD
    Issues[All Collected Issues] --> Filter[Filter by Severity]
    Filter --> Graph[Build Dependency Graph]
    Graph --> Traverse[Traverse Relationships]
    
    subgraph "Root Cause Logic"
        Traverse --> Check1{Has Incoming<br/>CAUSES edges?}
        Check1 -->|No| Root[Mark as Root Cause]
        Check1 -->|Yes| Check2{Has High Impact<br/>Score?}
        Check2 -->|Yes| Primary[Mark as Primary Root]
        Check2 -->|No| Secondary[Mark as Secondary Root]
    end
    
    Root --> Rank[Rank by Impact]
    Primary --> Rank
    Secondary --> Rank
    Rank --> Results[Ordered Root Causes]
```

### Cascading Failure Detection

```mermaid
flowchart TD
    RootCause[Identified Root Cause] --> FindPaths[Find All Outgoing Paths]
    FindPaths --> TraceCascade[Trace Cascade Effects]
    
    subgraph "Cascade Analysis"
        TraceCascade --> Path1[Path 1: Root Рєњ A Рєњ B Рєњ C]
        TraceCascade --> Path2[Path 2: Root Рєњ D Рєњ E]
        TraceCascade --> Path3[Path 3: Root Рєњ F]
    end
    
    Path1 --> Impact1[Calculate Impact Score]
    Path2 --> Impact2[Calculate Impact Score]
    Path3 --> Impact3[Calculate Impact Score]
    
    Impact1 --> Combine[Combine All Cascades]
    Impact2 --> Combine
    Impact3 --> Combine
    
    Combine --> Report[Cascade Report]
```

### Issue Clustering

```mermaid
flowchart TD
    AllIssues[All Issues] --> GroupBy[Group by Similarity]
    
    subgraph "Clustering Criteria"
        GroupBy --> Type[Issue Type]
        GroupBy --> Node[Affected Node]
        GroupBy --> Timing[Time Correlation]
        GroupBy --> Symptoms[Similar Symptoms]
    end
    
    Type --> Cluster1[Storage Cluster]
    Node --> Cluster2[Node-Specific Cluster]
    Timing --> Cluster3[Time-Correlated Cluster]
    Symptoms --> Cluster4[Symptom-Based Cluster]
    
    Cluster1 --> Analyze[Analyze Cluster Patterns]
    Cluster2 --> Analyze
    Cluster3 --> Analyze
    Cluster4 --> Analyze
    
    Analyze --> ClusterReport[Cluster Analysis Report]
```

## ­Ъј» Comprehensive Analysis Output

### Analysis Structure

```mermaid
graph TD
    subgraph "Comprehensive Results"
        Summary[Summary Statistics]
        
        subgraph "Visual Components"
            GraphViz[Knowledge Graph Visualization]
            FlowChart[Issue Flow Diagram]
        end
        
        subgraph "Analysis Reports"
            RootCauses[Root Cause Analysis]
            Cascades[Cascading Failures]
            Clusters[Issue Clusters]
        end
        
        subgraph "Action Plans"
            ComprehensivePlan[Comprehensive Fix Plan]
            PriorityOrder[Fix Priority Order]
            Dependencies[Fix Dependencies]
        end
    end
```

### Sample Output Format

```
=== COMPREHENSIVE STORAGE TROUBLESHOOTING RESULTS ===

SUMMARY:
  Total Issues Found: 7
  Critical Issues: 1
  High Priority Issues: 3
  Primary Issue: Disk Full on Node1 (CRITICAL)

KNOWLEDGE GRAPH VISUALIZATION:
РћїРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћљ    CAUSES    РћїРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћљ
Рћѓ Disk Full (CRITICAL)РћѓРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРєњРћѓ Pod Mount Fail (HIGH)Рћѓ
РћћРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћў              РћћРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћў
           Рћѓ                                     Рћѓ
           Рћѓ CAUSES                              Рћѓ AFFECTS
           РєЊ                                     РєЊ
РћїРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћљ              РћїРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћљ
Рћѓ Log Errors (MEDIUM) Рћѓ              Рћѓ Slow I/O (MEDIUM)  Рћѓ
РћћРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћў              РћћРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћђРћў

ROOT CAUSES (Ordered by Impact):
  1. Disk Full on /var/lib/kubelet (CRITICAL)
     Resource: Node/worker-node-1
     Description: Available disk space < 1GB
     Node: worker-node-1

CASCADING FAILURE PATTERNS:
  Source: Disk Full on /var/lib/kubelet
  Impact Chain: Disk Full Рєњ Pod Mount Fail Рєњ Application Errors Рєњ User Impact
  Affected Components: 4

=== COMPREHENSIVE ROOT CAUSE ANALYSIS ===
The primary root cause is insufficient disk space on worker-node-1's /var/lib/kubelet 
partition. This has cascaded to cause pod mount failures, which in turn affect 
application performance and user experience...

=== COMPREHENSIVE FIX PLAN ===
IMMEDIATE ACTIONS (Critical):
1. Clean up unused container images on worker-node-1
2. Expand /var/lib/kubelet partition
3. Restart failed pods

PREVENTIVE MEASURES (High):
4. Implement disk space monitoring
5. Configure log rotation policies
6. Set up storage capacity alerts

LONG-TERM IMPROVEMENTS (Medium):
7. Review storage allocation policies
8. Implement automated cleanup procedures
```

## ­Ъџђ Usage Examples

### Basic Comprehensive Analysis

```bash
# Run comprehensive analysis for a failing pod
python run_comprehensive_mode.py \
  --pod-name nginx-deployment-abc123 \
  --namespace production \
  --volume-path /var/www/html
```

### Advanced Configuration

```python
# Programmatic usage
from issue_collector import ComprehensiveIssueCollector
from knowledge_graph import IssueKnowledgeGraph

collector = ComprehensiveIssueCollector(k8s_client, config)
graph = await collector.collect_comprehensive_issues(
    pod_name="nginx-deployment-abc123",
    namespace="production", 
    volume_path="/var/www/html",
    tool_executor=execute_tool_mock
)

analysis = graph.generate_comprehensive_analysis()
```

## ­ЪћД Configuration Options

### Comprehensive Mode Settings

```yaml
comprehensive_mode:
  # Maximum issues to collect per layer
  max_issues_per_layer: 20
  
  # Analysis depth (1-5, higher = more thorough)
  analysis_depth: 3
  
  # Enable specific analysis types
  enable_cascading_analysis: true
  enable_clustering: true
  enable_trend_analysis: false
  
  # Relationship detection sensitivity
  relationship_threshold: 0.7
  
  # Output format options
  include_graph_visualization: true
  include_detailed_logs: false
  max_root_causes_displayed: 5
```

## ­Ъј» Best Practices

### When to Use Comprehensive Mode

1. **Complex Multi-Component Failures**: When simple troubleshooting doesn't reveal root causes
2. **Recurring Issues**: Patterns that suggest systemic problems
3. **High-Impact Outages**: Critical incidents requiring thorough analysis
4. **Post-Incident Analysis**: Understanding full scope of problems
5. **Capacity Planning**: Identifying bottlenecks and scaling needs

### Performance Considerations

- **Analysis Time**: Comprehensive mode takes 2-5x longer than single mode
- **Resource Usage**: Higher memory usage due to knowledge graph storage
- **Network Overhead**: More API calls to gather comprehensive data
- **Storage Requirements**: Detailed logs and analysis results

### Interpretation Guidelines

1. **Focus on Root Causes**: Address root causes before symptoms
2. **Consider Dependencies**: Fix critical dependencies first
3. **Validate Fixes**: Use single mode to verify each fix
4. **Monitor Trends**: Track improvement over time
5. **Document Patterns**: Build organizational knowledge

## ­ЪЏа№ИЈ Extending Comprehensive Mode

### Adding New Issue Types

```python
# In knowledge_graph.py
class IssueType(Enum):
    # Add new issue type
    CUSTOM_STORAGE_ERROR = "custom_storage_error"

# In issue_collector.py
async def collect_custom_issues(self, context: Dict[str, Any]) -> List[IssueNode]:
    """Collect custom storage issues"""
    # Implementation for detecting custom issues
    pass
```

### Custom Analysis Algorithms

```python
# Add custom analysis in knowledge_graph.py
def custom_analysis_algorithm(self) -> Dict[str, Any]:
    """Custom analysis algorithm"""
    # Implement custom logic
    return analysis_results
```

## ­ЪЊѕ Monitoring and Metrics

### Key Metrics

- **Issues Detected**: Total number of issues found per analysis
- **Root Cause Accuracy**: Percentage of correctly identified root causes
- **Fix Success Rate**: Percentage of issues resolved by recommended fixes
- **Analysis Time**: Time taken for comprehensive analysis
- **Cascade Detection**: Number of cascading failures identified

### Performance Tracking

```mermaid
graph LR
    Metrics[Analysis Metrics] --> Dashboard[Monitoring Dashboard]
    Dashboard --> Alerts[Performance Alerts]
    Alerts --> Optimization[Performance Optimization]
    Optimization --> Metrics
```

---

**Comprehensive Mode enables deep, systematic analysis of complex storage issues across your entire Kubernetes infrastructure.**
