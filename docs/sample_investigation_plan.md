# Sample Investigation Plan

This document provides a sample Investigation Plan generated by the Plan Phase for a volume read/write error in a Kubernetes cluster. The plan is generated based on the Knowledge Graph from Phase 0 and is designed to be executed by Phase 1 using the ReAct framework.

## Example Knowledge Graph Context

```json
{
  "nodes": [
    {"id": "log1", "type": "log", "attributes": {"timestamp": "2025-05-30T12:00:00", "message": "I/O error on volume for pod 'app-1'"}},
    {"id": "pod1", "type": "pod", "attributes": {"name": "app-1", "namespace": "default", "status": "Running"}},
    {"id": "pvc1", "type": "pvc", "attributes": {"name": "data-pvc", "storageClass": "standard", "bound": true}},
    {"id": "pv1", "type": "pv", "attributes": {"name": "pv-001", "capacity": "10Gi"}},
    {"id": "disk1", "type": "disk", "attributes": {"node": "node-1", "status": "online"}}
  ],
  "relationships": [
    {"source": "log1", "target": "pod1", "type": "affects"},
    {"source": "pod1", "target": "pvc1", "type": "uses"},
    {"source": "pvc1", "target": "pv1", "type": "binds"}
  ],
  "issues": [
    {
      "id": "issue1",
      "type": "io_error",
      "severity": "critical",
      "message": "I/O error on volume for pod 'app-1'",
      "node_id": "pod1",
      "timestamp": "2025-05-30T12:00:00"
    },
    {
      "id": "issue2",
      "type": "disk_health",
      "severity": "high",
      "message": "SMART health check failed for disk on node-1",
      "node_id": "disk1",
      "timestamp": "2025-05-30T11:55:00"
    }
  ]
}
```

## Example Phase 1 Tool Registry

```json
{
  "knowledge_graph": [
    {
      "name": "kg_query_nodes",
      "description": "Queries nodes in the Knowledge Graph by type and optional time range",
      "parameters": [
        {"name": "type", "type": "string", "required": true},
        {"name": "time_range", "type": "string", "required": false}
      ]
    },
    {
      "name": "kg_query_relationships",
      "description": "Queries relationships between specified source and target node types",
      "parameters": [
        {"name": "source", "type": "string", "required": true},
        {"name": "target", "type": "string", "required": true}
      ]
    },
    {
      "name": "kg_get_node_metadata",
      "description": "Retrieves metadata for nodes of the specified type",
      "parameters": [
        {"name": "node_type", "type": "string", "required": true}
      ]
    }
  ],
  "kubernetes": [
    {
      "name": "kubectl_get_pod",
      "description": "Gets detailed information about a pod",
      "parameters": [
        {"name": "namespace", "type": "string", "required": true},
        {"name": "pod_name", "type": "string", "required": true}
      ]
    },
    {
      "name": "kubectl_get_pvc",
      "description": "Gets detailed information about a PVC",
      "parameters": [
        {"name": "namespace", "type": "string", "required": true},
        {"name": "pvc_name", "type": "string", "required": true}
      ]
    }
  ],
  "system_diagnostics": [
    {
      "name": "check_disk_health",
      "description": "Checks the health of a disk on a specific node",
      "parameters": [
        {"name": "node", "type": "string", "required": true},
        {"name": "disk_id", "type": "string", "required": true}
      ]
    },
    {
      "name": "df_check",
      "description": "Checks disk space usage on a node",
      "parameters": [
        {"name": "node", "type": "string", "required": true}
      ]
    }
  ]
}
```

## Example LLM-Generated Investigation Plan

```
Investigation Plan:
Target: Pod default/app-1, Volume Path: /data
Generated Steps: 5 main steps, 3 fallback steps

HYPOTHESES ANALYSIS:
1. Disk Hardware Failure (High Likelihood)
   - Evidence: SMART health check failure on disk1 (issue2)
   - Timing: Disk health issue occurred 5 minutes before I/O error
   - Relationship: disk1 is on node-1 which hosts the affected pod

2. PVC/PV Binding Issue (Medium Likelihood)
   - Evidence: PVC is bound but no direct relationship to disk1 in Knowledge Graph
   - Missing relationship between PV and physical disk could indicate misconfiguration

3. File System Corruption (Medium Likelihood)
   - Evidence: I/O error without disk offline status
   - Disk shows as "online" despite health check failure

4. Storage Class Misconfiguration (Low Likelihood)
   - Evidence: No direct issues with storage class in Knowledge Graph
   - Standard storage class is used which should be properly configured

Step 1: Query recent error logs for volume issues | Tool: kg_query_nodes(type='log', time_range='24h') | Expected: List of I/O error logs for pod 'app-1', confirming error patterns and frequency

Step 2: Check disk health for the node hosting the volume | Tool: check_disk_health(node='node-1', disk_id='disk1') | Expected: Disk status and any hardware errors to confirm Hypothesis 1

Step 3: Verify pod-to-PVC binding using | Tool: kg_query_relationships(source='pod', target='pvc') | Expected: Confirm 'app-1' is correctly bound to 'data-pvc' to evaluate Hypothesis 2

Step 4: Check disk space usage on the node | Tool: df_check(node='node-1') | Expected: Disk space usage to determine if the volume is full, which could cause I/O errors

Step 5: Retrieve PVC and PV metadata | Tool: kg_get_node_metadata(node_type='pvc') | Expected: Configuration details to identify misconfigurations related to Hypothesis 2 and 4

Fallback Steps (if main steps fail):
Step F1: Get pod details directly from Kubernetes | Tool: kubectl_get_pod(namespace='default', pod_name='app-1') | Expected: Pod status and events from Kubernetes API | Trigger: kg_query_nodes_failure

Step F2: Get PVC details directly from Kubernetes | Tool: kubectl_get_pvc(namespace='default', pvc_name='data-pvc') | Expected: PVC status and details from Kubernetes API | Trigger: kg_query_relationships_failure

Step F3: Perform general node diagnostics | Tool: node_diagnostics(node='node-1') | Expected: Overall node health and resource usage | Trigger: check_disk_health_failure
```

## Example Rule-Based Investigation Plan

```
Investigation Plan:
Target: Pod default/app-1, Volume Path: /data
Generated Steps: 7 main steps, 3 fallback steps

Step 1: Get all critical and high severity issues from Knowledge Graph | Tool: kg_get_all_issues(severity='critical') | Expected: List of critical issues that may be causing volume I/O errors

Step 2: Analyze issue patterns and relationships to identify root causes | Tool: kg_analyze_issues() | Expected: Root cause analysis with probability scores and relationship patterns

Step 3: Get high severity issues that may be related to the volume problem | Tool: kg_get_all_issues(severity='high') | Expected: High severity issues for comprehensive analysis

Step 4: Get detailed information about the problem pod and its current state | Tool: kg_get_entity_info(entity_type='Pod', entity_id='app-1') | Expected: Pod configuration, status, and any detected issues

Step 5: Find all entities related to the problem pod (PVC, PV, Node, etc.) | Tool: kg_get_related_entities(entity_type='Pod', entity_id='app-1', max_depth=2) | Expected: Complete dependency chain from Pod to underlying storage

Step 6: Get detailed Drive information including health status and metrics | Tool: kg_get_entity_info(entity_type='Drive', entity_id='disk1') | Expected: Drive health status, SMART data, and any hardware issues

Step 7: Get overall Knowledge Graph summary for system health context | Tool: kg_get_summary() | Expected: System overview with entity counts and issue statistics

Fallback Steps (if main steps fail):
Step F1: If specific entity lookup fails, get all medium severity issues | Tool: kg_get_all_issues(severity='medium') | Expected: Medium severity issues for broader analysis | Trigger: entity_not_found

Step F2: If no specific issues found, search for all Drive entities | Tool: kg_get_related_entities(entity_type='Drive', entity_id='any', max_depth=1) | Expected: List of all Drive entities for manual inspection | Trigger: no_issues_found

Step F3: If investigation data is incomplete, print full Knowledge Graph | Tool: kg_print_graph(include_details=True, include_issues=True) | Expected: Complete Knowledge Graph visualization for manual analysis | Trigger: insufficient_data
```

## Structured Plan Format for Phase 1

The Plan Phase also provides a structured JSON format of the Investigation Plan for Phase 1 to consume programmatically:

```json
{
  "steps": [
    {
      "step": "1",
      "description": "Query recent error logs for volume issues",
      "tool": "kg_query_nodes",
      "arguments": {
        "type": "log",
        "time_range": "24h"
      },
      "expected": "List of I/O error logs for pod 'app-1', confirming error patterns and frequency"
    },
    {
      "step": "2",
      "description": "Check disk health for the node hosting the volume",
      "tool": "check_disk_health",
      "arguments": {
        "node": "node-1",
        "disk_id": "disk1"
      },
      "expected": "Disk status and any hardware errors to confirm Hypothesis 1"
    },
    {
      "step": "3",
      "description": "Verify pod-to-PVC binding",
      "tool": "kg_query_relationships",
      "arguments": {
        "source": "pod",
        "target": "pvc"
      },
      "expected": "Confirm 'app-1' is correctly bound to 'data-pvc' to evaluate Hypothesis 2"
    },
    {
      "step": "4",
      "description": "Check disk space usage on the node",
      "tool": "df_check",
      "arguments": {
        "node": "node-1"
      },
      "expected": "Disk space usage to determine if the volume is full, which could cause I/O errors"
    },
    {
      "step": "5",
      "description": "Retrieve PVC and PV metadata",
      "tool": "kg_get_node_metadata",
      "arguments": {
        "node_type": "pvc"
      },
      "expected": "Configuration details to identify misconfigurations related to Hypothesis 2 and 4"
    }
  ],
  "fallback_steps": [
    {
      "step": "F1",
      "description": "Get pod details directly from Kubernetes",
      "tool": "kubectl_get_pod",
      "arguments": {
        "namespace": "default",
        "pod_name": "app-1"
      },
      "expected": "Pod status and events from Kubernetes API",
      "trigger": "kg_query_nodes_failure"
    },
    {
      "step": "F2",
      "description": "Get PVC details directly from Kubernetes",
      "tool": "kubectl_get_pvc",
      "arguments": {
        "namespace": "default",
        "pvc_name": "data-pvc"
      },
      "expected": "PVC status and details from Kubernetes API",
      "trigger": "kg_query_relationships_failure"
    },
    {
      "step": "F3",
      "description": "Perform general node diagnostics",
      "tool": "node_diagnostics",
      "arguments": {
        "node": "node-1"
      },
      "expected": "Overall node health and resource usage",
      "trigger": "check_disk_health_failure"
    }
  ]
}
```

## Integration with Phase 1

Phase 1 uses the structured plan to execute the investigation steps using the ReAct framework. Each step is executed in order, with the results of each step informing the next. If a step fails, the corresponding fallback step is executed based on the trigger condition.

The Investigation Plan provides a deterministic, prioritized sequence of actions for Phase 1 to follow, ensuring that the most likely causes of the volume read/write error are investigated first.
