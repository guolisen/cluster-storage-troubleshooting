#!/usr/bin/env python3
"""
Phase 1: ReAct Investigation for Kubernetes Volume Troubleshooting

This module contains the implementation of Phase 1 (ReAct Investigation)
which actively investigates using tools with pre-collected data as base knowledge.
"""

import logging
import asyncio
import datetime
from typing import Dict, List, Any, Optional, Tuple
from rich.console import Console
from rich.panel import Panel
from langgraph.graph import StateGraph
from kubernetes import client
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage

from troubleshooting.graph import create_troubleshooting_graph_with_context
from tools.diagnostics.hardware import xfs_repair_check  # Importing the xfs_repair_check tool
from phases.utils import format_historical_experiences_from_collected_info, handle_exception

logger = logging.getLogger(__name__)

class AnalysisPhase:
    """
    Implementation of Phase 1: ReAct Investigation
    
    This class handles the active investigation of volume I/O errors
    using the Investigation Plan and pre-collected data.
    """
    
    def __init__(self, collected_info: Dict[str, Any], config_data: Dict[str, Any]):
        """
        Initialize the Analysis Phase
        
        Args:
            collected_info: Pre-collected diagnostic information from Phase 0
            config_data: Configuration data for the system
        """
        self.collected_info = collected_info
        self.config_data = config_data
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")
        self.console = Console()

    def _extract_final_message(self, response: Dict[str, Any]) -> str:
        """
        Extract the final message from a graph response
        
        Args:
            response: Response from the graph
            
        Returns:
            str: Final message content
        """
        if not response.get("messages"):
            return "Failed to generate analysis results"
            
        if isinstance(response["messages"], list):
            return response["messages"][-1].content
        else:
            return response["messages"].content
    
    async def run_investigation(self, pod_name: str, namespace: str, volume_path: str, 
                               investigation_plan: str, message_list: List[Dict[str, str]] = None) -> Tuple[str, List[Dict[str, str]]]:
        """
        Run the investigation based on the Investigation Plan
        
        Args:
            pod_name: Name of the pod with the error
            namespace: Namespace of the pod
            volume_path: Path of the volume with I/O error
            investigation_plan: Investigation Plan generated by the Plan Phase
            message_list: Optional message list for chat mode
            
        Returns:
            Tuple[str, List[Dict[str, str]]]: (Analysis result, Updated message list)
        """
        try:
            if message_list == None:
                message_list = []

            # Create troubleshooting graph with pre-collected context
            graph = create_troubleshooting_graph_with_context(
                self.collected_info, phase="phase1", config_data=self.config_data
            )
            
            # Extract and format historical experience data from collected_info
            historical_experiences_formatted = format_historical_experiences_from_collected_info(self.collected_info)
            
            # Add investigation results to message list if not already present
            message_list.append({"role": "user", "content": "Investigation Results:\n" + investigation_plan})
            
            # Updated query message with dynamic data for LangGraph workflow
            query = f"""Phase 1 - ReAct Investigation: Execute the Investigation Plan to actively investigate the volume I/O error in pod {pod_name} in namespace {namespace} at volume path {volume_path}.

INVESTIGATION PLAN TO FOLLOW:
{investigation_plan}

HISTORICAL EXPERIENCE:
{historical_experiences_formatted}

SPECIAL CASE DETECTION:
After executing the Investigation Plan, you must determine if one of these special cases applies:

CASE 1 - NO ISSUES DETECTED:
If the Knowledge Graph and Investigation Plan execution confirm the system has no issues:
- Output a structured summary in the following format:
  ```
  Summary Finding: No issues detected in the system.
  Evidence: [Details from Knowledge Graph queries, e.g., no error logs found, all services operational]
  Advice: [Recommendations, e.g., continue monitoring the system]
  SKIP_PHASE2: YES
  ```

CASE 2 - MANUAL INTERVENTION REQUIRED:
If the Knowledge Graph and Investigation Plan execution confirm the issue cannot be fixed automatically:
- Output a structured summary in the following format:
  ```
  Summary Finding: Issue detected, but requires manual intervention.
  Evidence: [Details from Knowledge Graph queries, e.g., specific error or configuration requiring human action]
  Advice: [Detailed step-by-step instructions for manual resolution, e.g., specific commands or actions for the user]
  SKIP_PHASE2: YES
  ```

CASE 3 - AUTOMATIC FIX POSSIBLE:
If the issue can be resolved automatically:
- Generate a fix plan based on the Investigation Plan's results
- Output a comprehensive root cause analysis and fix plan
- Do NOT include the SKIP_PHASE2 marker

<<< Note >>>: Please following the Investigation Plan to run tools step by step, and run 8 steps at least.
<<< Note >>>: Please provide the root cause and fix plan analysis within 30 tool calls.
"""
            # Set timeout
            timeout_seconds = self.config_data['troubleshoot']['timeout_seconds']
            
            # Run analysis using the tools module
            formatted_query = {"messages": [{"role": "user", "content": query}]}
            
            # First show the analysis panel
            self.console.print(Panel(
                "[yellow]Starting analysis with LangGraph...\nThis may take a few minutes to complete.", 
                title="[bold blue]Analysis Phase",
                border_style="blue"
            ))
            
            # Run graph with timeout
            try:
                response = await asyncio.wait_for(
                    graph.ainvoke(formatted_query, config={"recursion_limit": 100}),
                    timeout=timeout_seconds
                )
                self.console.print("[green]Analysis complete![/green]")
            except asyncio.TimeoutError:
                self.console.print("[red]Analysis timed out![/red]")
                raise
            except Exception as e:
                self.console.print(f"[red]Analysis failed: {str(e)}[/red]")
                raise
            
            # Extract analysis results
            final_message = self._extract_final_message(response)
            
            # Add fix plan to message list
            message_list.append({"role": "assistant", "content": final_message})
            
            return final_message, message_list

        except Exception as e:
            error_msg = handle_exception("run_investigation", e, self.logger)
            
            # Add error message to message list if provided
            if message_list is not None:
                message_list.append({"role": "assistant", "content": error_msg})
            
            return error_msg, message_list


def summarize_investigation_results(results: str, llm) -> str:
    """
    Use LLM to summarize investigation results into a concise message (≤1024 chars)
    
    Args:
        results: Investigation results from Phase1
        llm: LLM instance to use for summarization
        
    Returns:
        str: Summarized investigation results (≤1024 chars)
    """
    # Prompt the LLM to summarize the results
    prompt = "Summarize the investigation results for Kubernetes pod volume I/O failures into a concise message under 1024 characters, highlighting primary issues."
    
    # Create messages for the LLM
    messages = [
        SystemMessage(content="You are an expert Kubernetes storage troubleshooter. Your task is to summarize investigation results concisely."),
        HumanMessage(content=f"{prompt}\n\nInvestigation Results:\n{results}")
    ]
    
    try:
        # Call the LLM
        response = llm.invoke(messages)
        
        # Extract the summary
        summary = response.content.strip()
        
        # Truncate if necessary
        if len(summary) > 1024:
            summary = summary[:1020] + "..."
            
        return summary
    except Exception as e:
        logging.error(f"Error in summarize_investigation_results: {e}")
        # Return a basic summary in case of failure
        return f"Investigation completed. Error generating detailed summary: {str(e)[:100]}..."

def send_k8s_event(namespace: str, resource_name: str, resource_kind: str, message: str) -> bool:
    """
    Send a Kubernetes event with investigation results
    
    Args:
        namespace: Namespace of the resource
        resource_name: Name of the resource
        resource_kind: Kind of the resource (e.g., Pod)
        message: Event message containing investigation summary
        
    Returns:
        bool: True if event was sent successfully, False otherwise
    """
    try:
        # Create Kubernetes API client
        v1 = client.CoreV1Api()
        
        # Create event metadata
        metadata = client.V1ObjectMeta(
            generate_name="troubleshooting-",
            namespace=namespace
        )
        
        # Create involved object reference
        involved_object = client.V1ObjectReference(
            kind=resource_kind,
            namespace=namespace,
            name=resource_name
        )
        
        # Create event source
        source = client.V1EventSource(
            component="troubleshooting-system"
        )
        
        # Create event
        event = client.CoreV1Event(
            metadata=metadata,
            involved_object=involved_object,
            reason="VolumeIOError",
            message=message,
            type="Error",
            source=source,
            first_timestamp=datetime.datetime.now(datetime.timezone.utc).isoformat(),
            last_timestamp=datetime.datetime.now(datetime.timezone.utc).isoformat(),
        )
        
        # Send event
        v1.create_namespaced_event(namespace, event)
        
        logging.info(f"Kubernetes event sent successfully for {resource_kind}/{resource_name} in namespace {namespace}")
        return True
    except Exception as e:
        logging.error(f"Error sending Kubernetes event: {e}")
        return False


async def run_analysis_phase_with_plan(pod_name: str, namespace: str, volume_path: str, 
                                     collected_info: Dict[str, Any], investigation_plan: str,
                                     config_data: Dict[str, Any], message_list: List[Dict[str, str]] = None) -> Tuple[str, bool, List[Dict[str, str]]]:
    """
    Run Phase 1: ReAct Investigation with pre-collected information as base knowledge
    
    Args:
        pod_name: Name of the pod with the error
        namespace: Namespace of the pod
        volume_path: Path of the volume with I/O error
        collected_info: Pre-collected diagnostic information from Phase 0
        investigation_plan: Investigation Plan generated by the Plan Phase
        config_data: Configuration data
        message_list: Optional message list for chat mode
        
    Returns:
        Tuple[str, bool, List[Dict[str, str]]]: (Analysis result, Skip Phase2 flag, Updated message list)
    """
    logging.info("Starting Phase 1: ReAct Investigation with Plan")
    
    console = Console()
    console.print("\n")
    console.print(Panel(
        "[bold white]Executing Investigation Plan to actively investigate volume I/O issue...",
        title="[bold magenta]PHASE 1: REACT INVESTIGATION WITH PLAN",
        border_style="magenta",
        padding=(1, 2)
    ))
    
    try:
        # Initialize the analysis phase
        phase = AnalysisPhase(collected_info, config_data)
        
        # Run the investigation
        result, message_list = await phase.run_investigation(pod_name, namespace, volume_path, investigation_plan, message_list)

        # Process the result
        return process_analysis_result(result, message_list, pod_name, namespace, config_data)
    
    except Exception as e:
        error_msg = handle_exception("run_analysis_phase_with_plan", e, logger)
        
        # Add error message to message list if provided
        if message_list is not None:
            message_list.append({"role": "assistant", "content": error_msg})
        
        return error_msg, False, message_list

def process_analysis_result(result: str, message_list: List[Dict[str, str]], pod_name: str, namespace: str, config_data: Dict[str, Any]) -> Tuple[str, bool, List[Dict[str, str]]]:
    """
    Process the analysis result to check for SKIP_PHASE2 marker and send Kubernetes event
    
    Args:
        result: Analysis result
        message_list: Message list for chat mode
        pod_name: Name of the pod with the error
        namespace: Namespace of the pod
        config_data: Configuration data
        
    Returns:
        Tuple[str, bool, List[Dict[str, str]]]: (Processed result, Skip Phase2 flag, Message list)
    """
    # Check if the result contains the SKIP_PHASE2 marker
    skip_phase2 = "SKIP_PHASE2: YES" in result
    
    # Remove the SKIP_PHASE2 marker from the output if present
    if skip_phase2:
        result = result.replace("SKIP_PHASE2: YES", "").strip()
        logging.info("Phase 1 indicated Phase 2 should be skipped")
    
    # Initialize LLM for summarization
    try:

        # Get LLM configuration
        llm_config = config_data.get('llm', {})
        
        # Initialize LLM with configuration
        llm = ChatOpenAI(
            model=llm_config.get('model', 'gpt-4'),
            api_key=llm_config.get('api_key', None),
            base_url=llm_config.get('api_endpoint', None),
            temperature=llm_config.get('temperature', 0.1),
            max_tokens=llm_config.get('max_tokens', 8192)
        )

        # Generate summary of investigation results
        summary = summarize_investigation_results(result, llm)
        logging.info(f"Event Summary: {summary}")

        # Send Kubernetes event
        event_sent = send_k8s_event(namespace, pod_name, "Pod", summary)
        
        if event_sent:
            logging.info(f"Kubernetes event sent with investigation summary for pod {namespace}/{pod_name}")
        else:
            logging.warning(f"Failed to send Kubernetes event for pod {namespace}/{pod_name}")
    except Exception as e:
        logging.error(f"Error during event creation: {e}")
    
    return result, skip_phase2, message_list
